{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Rocket transformer.\"\"\"\n",
    "\n",
    "__author__ = \"angus924\"\n",
    "__all__ = [\"Rocket\"]\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import get_num_threads, njit, prange, set_num_threads\n",
    "\n",
    "from sktime.transformations.base import BaseTransformer\n",
    "\n",
    "\n",
    "class Rocket(BaseTransformer):\n",
    "    \"\"\"ROCKET.\n",
    "\n",
    "    RandOm Convolutional KErnel Transform\n",
    "\n",
    "    @article{dempster_etal_2019,\n",
    "      author  = {Dempster, Angus and Petitjean, Francois and Webb,\n",
    "      Geoffrey I},\n",
    "      title   = {ROCKET: Exceptionally fast and accurate time series\n",
    "      classification using random convolutional kernels},\n",
    "      year    = {2019},\n",
    "      journal = {arXiv:1910.13051}\n",
    "    }\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_kernels  : int, number of random convolutional kernels (default 10,000)\n",
    "    normalise    : boolean, whether or not to normalise the input time\n",
    "    series per instance (default True)\n",
    "    n_jobs             : int, optional (default=1) The number of jobs to run in\n",
    "    parallel for `transform`. ``-1`` means using all processors.\n",
    "    random_state : int (ignored unless int due to compatability with Numba),\n",
    "    random seed (optional, default None)\n",
    "    \"\"\"\n",
    "\n",
    "    _tags = {\n",
    "        \"univariate-only\": False,\n",
    "        \"fit_is_empty\": False,\n",
    "        \"scitype:transform-input\": \"Series\",\n",
    "        # what is the scitype of X: Series, or Panel\n",
    "        \"scitype:transform-output\": \"Primitives\",\n",
    "        # what is the scitype of y: None (not needed), Primitives, Series, Panel\n",
    "        \"scitype:instancewise\": False,  # is this an instance-wise transform?\n",
    "        \"X_inner_mtype\": \"numpy3D\",  # which mtypes do _fit/_predict support for X?\n",
    "        \"y_inner_mtype\": \"None\",  # which mtypes do _fit/_predict support for X?\n",
    "    }\n",
    "\n",
    "    def __init__(self, num_kernels=10_000, normalise=True, n_jobs=1, random_state=None):\n",
    "        self.num_kernels = num_kernels\n",
    "        self.normalise = normalise\n",
    "        self.n_jobs = n_jobs\n",
    "        self.random_state = random_state if isinstance(random_state, int) else None\n",
    "        super(Rocket, self).__init__()\n",
    "\n",
    "    def _fit(self, X, y=None):\n",
    "        \"\"\"Generate random kernels adjusted to time series shape.\n",
    "\n",
    "        Infers time series length and number of channels / dimensions (\n",
    "        for multivariate time series) from input pandas DataFrame,\n",
    "        and generates random kernels.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 3D np.ndarray of shape = [n_instances, n_dimensions, series_length]\n",
    "            panel of time series to transform\n",
    "        y : ignored argument for interface compatibility\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        _, self.n_columns, n_timepoints = X.shape\n",
    "        self.kernels = _generate_kernels(\n",
    "            n_timepoints, self.num_kernels, self.n_columns, self.random_state\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def _transform(self, X, y=None):\n",
    "        \"\"\"Transform input time series using random convolutional kernels.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 3D np.ndarray of shape = [n_instances, n_dimensions, series_length]\n",
    "            panel of time series to transform\n",
    "        y : ignored argument for interface compatibility\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pandas DataFrame, transformed features\n",
    "        \"\"\"\n",
    "        if self.normalise:\n",
    "            X = (X - X.mean(axis=-1, keepdims=True)) / (\n",
    "                X.std(axis=-1, keepdims=True) + 1e-8\n",
    "            )\n",
    "        prev_threads = get_num_threads()\n",
    "        if self.n_jobs < 1 or self.n_jobs > multiprocessing.cpu_count():\n",
    "            n_jobs = multiprocessing.cpu_count()\n",
    "        else:\n",
    "            n_jobs = self.n_jobs\n",
    "        set_num_threads(n_jobs)\n",
    "        t = pd.DataFrame(_apply_kernels(X.astype(np.float32), self.kernels))\n",
    "        set_num_threads(prev_threads)\n",
    "        return t\n",
    "\n",
    "\n",
    "@njit(\n",
    "    \"Tuple((float32[:],int32[:],float32[:],int32[:],int32[:],int32[:],\"\n",
    "    \"int32[:]))(int32,int32,int32,optional(int32))\",\n",
    "    cache=True,\n",
    ")\n",
    "def _generate_kernels(n_timepoints, num_kernels, n_columns, seed):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    candidate_lengths = np.array((7, 9, 11), dtype=np.int32)\n",
    "    lengths = np.random.choice(candidate_lengths, num_kernels).astype(np.int32)\n",
    "\n",
    "    num_channel_indices = np.zeros(num_kernels, dtype=np.int32)\n",
    "    for i in range(num_kernels):\n",
    "        limit = min(n_columns, lengths[i])\n",
    "        num_channel_indices[i] = 2 ** np.random.uniform(0, np.log2(limit + 1))\n",
    "\n",
    "    channel_indices = np.zeros(num_channel_indices.sum(), dtype=np.int32)\n",
    "\n",
    "    weights = np.zeros(\n",
    "        np.int32(\n",
    "            np.dot(lengths.astype(np.float32), num_channel_indices.astype(np.float32))\n",
    "        ),\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "    biases = np.zeros(num_kernels, dtype=np.float32)\n",
    "    dilations = np.zeros(num_kernels, dtype=np.int32)\n",
    "    paddings = np.zeros(num_kernels, dtype=np.int32)\n",
    "\n",
    "    a1 = 0  # for weights\n",
    "    a2 = 0  # for channel_indices\n",
    "\n",
    "    for i in range(num_kernels):\n",
    "\n",
    "        _length = lengths[i]\n",
    "        _num_channel_indices = num_channel_indices[i]\n",
    "\n",
    "        _weights = np.random.normal(0, 1, _num_channel_indices * _length).astype(\n",
    "            np.float32\n",
    "        )\n",
    "\n",
    "        b1 = a1 + (_num_channel_indices * _length)\n",
    "        b2 = a2 + _num_channel_indices\n",
    "\n",
    "        a3 = 0  # for weights (per channel)\n",
    "        for _ in range(_num_channel_indices):\n",
    "            b3 = a3 + _length\n",
    "            _weights[a3:b3] = _weights[a3:b3] - _weights[a3:b3].mean()\n",
    "            a3 = b3\n",
    "\n",
    "        weights[a1:b1] = _weights\n",
    "\n",
    "        channel_indices[a2:b2] = np.random.choice(\n",
    "            np.arange(0, n_columns), _num_channel_indices, replace=False\n",
    "        )\n",
    "\n",
    "        biases[i] = np.random.uniform(-1, 1)\n",
    "\n",
    "        dilation = 2 ** np.random.uniform(\n",
    "            0, np.log2((n_timepoints - 1) / (_length - 1))\n",
    "        )\n",
    "        dilation = np.int32(dilation)\n",
    "        dilations[i] = dilation\n",
    "\n",
    "        padding = ((_length - 1) * dilation) // 2 if np.random.randint(2) == 1 else 0\n",
    "        paddings[i] = padding\n",
    "\n",
    "        a1 = b1\n",
    "        a2 = b2\n",
    "\n",
    "    return (\n",
    "        weights,\n",
    "        lengths,\n",
    "        biases,\n",
    "        dilations,\n",
    "        paddings,\n",
    "        num_channel_indices,\n",
    "        channel_indices,\n",
    "    )\n",
    "\n",
    "\n",
    "@njit(fastmath=True, cache=True)\n",
    "def _apply_kernel_univariate(X, weights, length, bias, dilation, padding):\n",
    "    n_timepoints = len(X)\n",
    "\n",
    "    output_length = (n_timepoints + (2 * padding)) - ((length - 1) * dilation)\n",
    "\n",
    "    _ppv = 0\n",
    "    _max = np.NINF\n",
    "\n",
    "    end = (n_timepoints + padding) - ((length - 1) * dilation)\n",
    "\n",
    "    for i in range(-padding, end):\n",
    "\n",
    "        _sum = bias\n",
    "\n",
    "        index = i\n",
    "\n",
    "        for j in range(length):\n",
    "\n",
    "            if index > -1 and index < n_timepoints:\n",
    "                _sum = _sum + weights[j] * X[index]\n",
    "\n",
    "            index = index + dilation\n",
    "\n",
    "        if _sum > _max:\n",
    "            _max = _sum\n",
    "\n",
    "        if _sum > 0:\n",
    "            _ppv += 1\n",
    "\n",
    "    return np.float32(_ppv / output_length), np.float32(_max)\n",
    "\n",
    "\n",
    "@njit(fastmath=True, cache=True)\n",
    "def _apply_kernel_multivariate(\n",
    "    X, weights, length, bias, dilation, padding, num_channel_indices, channel_indices\n",
    "):\n",
    "    n_columns, n_timepoints = X.shape\n",
    "\n",
    "    output_length = (n_timepoints + (2 * padding)) - ((length - 1) * dilation)\n",
    "\n",
    "    _ppv = 0\n",
    "    _max = np.NINF\n",
    "\n",
    "    end = (n_timepoints + padding) - ((length - 1) * dilation)\n",
    "\n",
    "    for i in range(-padding, end):\n",
    "\n",
    "        _sum = bias\n",
    "\n",
    "        index = i\n",
    "\n",
    "        for j in range(length):\n",
    "\n",
    "            if index > -1 and index < n_timepoints:\n",
    "\n",
    "                for k in range(num_channel_indices):\n",
    "                    _sum = _sum + weights[k, j] * X[channel_indices[k], index]\n",
    "\n",
    "            index = index + dilation\n",
    "\n",
    "        if _sum > _max:\n",
    "            _max = _sum\n",
    "\n",
    "        if _sum > 0:\n",
    "            _ppv += 1\n",
    "\n",
    "    return np.float32(_ppv / output_length), np.float32(_max)\n",
    "\n",
    "\n",
    "@njit(\n",
    "    \"float32[:,:](float32[:,:,:],Tuple((float32[::1],int32[:],float32[:],\"\n",
    "    \"int32[:],int32[:],int32[:],int32[:])))\",\n",
    "    parallel=True,\n",
    "    fastmath=True,\n",
    "    cache=True,\n",
    ")\n",
    "def _apply_kernels(X, kernels):\n",
    "    (\n",
    "        weights,\n",
    "        lengths,\n",
    "        biases,\n",
    "        dilations,\n",
    "        paddings,\n",
    "        num_channel_indices,\n",
    "        channel_indices,\n",
    "    ) = kernels\n",
    "\n",
    "    n_instances, n_columns, _ = X.shape\n",
    "    num_kernels = len(lengths)\n",
    "\n",
    "    _X = np.zeros(\n",
    "        (n_instances, num_kernels * 2), dtype=np.float32\n",
    "    )  # 2 features per kernel\n",
    "\n",
    "    for i in prange(n_instances):\n",
    "\n",
    "        a1 = 0  # for weights\n",
    "        a2 = 0  # for channel_indices\n",
    "        a3 = 0  # for features\n",
    "\n",
    "        for j in range(num_kernels):\n",
    "\n",
    "            b1 = a1 + num_channel_indices[j] * lengths[j]\n",
    "            b2 = a2 + num_channel_indices[j]\n",
    "            b3 = a3 + 2\n",
    "\n",
    "            if num_channel_indices[j] == 1:\n",
    "\n",
    "                _X[i, a3:b3] = _apply_kernel_univariate(\n",
    "                    X[i, channel_indices[a2]],\n",
    "                    weights[a1:b1],\n",
    "                    lengths[j],\n",
    "                    biases[j],\n",
    "                    dilations[j],\n",
    "                    paddings[j],\n",
    "                )\n",
    "\n",
    "            else:\n",
    "\n",
    "                _weights = weights[a1:b1].reshape((num_channel_indices[j], lengths[j]))\n",
    "\n",
    "                _X[i, a3:b3] = _apply_kernel_multivariate(\n",
    "                    X[i],\n",
    "                    _weights,\n",
    "                    lengths[j],\n",
    "                    biases[j],\n",
    "                    dilations[j],\n",
    "                    paddings[j],\n",
    "                    num_channel_indices[j],\n",
    "                    channel_indices[a2:b2],\n",
    "                )\n",
    "\n",
    "            a1 = b1\n",
    "            a2 = b2\n",
    "            a3 = b3\n",
    "\n",
    "    return _X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('g:/My Drive/1-time-series classification in manufacturing/Code')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### get current path\n",
    "from pathlib import Path\n",
    "path = Path.cwd()\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The dataset shape is:(129, 112, 19)\n",
      "\n",
      " The number of data samples (N) is:129\n",
      "\n",
      " The number of TS length (T) is:112\n",
      "\n",
      " The number of TS dimention (M) is:19\n"
     ]
    }
   ],
   "source": [
    "## Load the dataset\n",
    "path_dir = 'g:/My Drive/1-time-series classification in manufacturing/Datasets'\n",
    "DSname = 'Etching_dataset'\n",
    "path = path_dir + \"/\" + DSname + \"/\"\n",
    "X_train = np.load(path + 'X_train.npy')\n",
    "X_test = np.load(path + 'X_test.npy')\n",
    "y_train = np.load(path + 'y_train.npy').reshape((-1,))\n",
    "y_test = np.load(path + 'y_test.npy').reshape((-1,))\n",
    "ts = np.concatenate((X_train, X_test), axis=0)\n",
    "\n",
    "print(f\"\\n The dataset shape is:{ts.shape}\")\n",
    "print(f\"\\n The number of data samples (N) is:{ts.shape[0]}\")\n",
    "print(f\"\\n The number of TS length (T) is:{ts.shape[1]}\")\n",
    "print(f\"\\n The number of TS dimention (M) is:{ts.shape[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.swapaxes(X_train, 1,2)\n",
    "X_test = np.swapaxes(X_test, 1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tranformer = Rocket(n_jobs=-1, num_kernels=2002)\n",
    "X_test_t = tranformer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 19, 112)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3994</th>\n",
       "      <th>3995</th>\n",
       "      <th>3996</th>\n",
       "      <th>3997</th>\n",
       "      <th>3998</th>\n",
       "      <th>3999</th>\n",
       "      <th>4000</th>\n",
       "      <th>4001</th>\n",
       "      <th>4002</th>\n",
       "      <th>4003</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.658537</td>\n",
       "      <td>7.738423</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>7.900820</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>2.199746</td>\n",
       "      <td>0.241071</td>\n",
       "      <td>4.738143</td>\n",
       "      <td>0.491071</td>\n",
       "      <td>6.531595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>8.045144</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>14.517509</td>\n",
       "      <td>0.401786</td>\n",
       "      <td>6.404209</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>4.759510</td>\n",
       "      <td>0.298077</td>\n",
       "      <td>5.525523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.670732</td>\n",
       "      <td>6.932831</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>7.754910</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>2.031164</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>6.846100</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>7.235452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410714</td>\n",
       "      <td>9.098060</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>14.165912</td>\n",
       "      <td>0.455357</td>\n",
       "      <td>5.934387</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>5.642019</td>\n",
       "      <td>0.298077</td>\n",
       "      <td>5.054339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.597561</td>\n",
       "      <td>8.786510</td>\n",
       "      <td>0.366071</td>\n",
       "      <td>6.649922</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>1.931009</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>5.858680</td>\n",
       "      <td>0.580357</td>\n",
       "      <td>7.380602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410714</td>\n",
       "      <td>10.986277</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>12.965539</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>6.995210</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>5.816529</td>\n",
       "      <td>0.240385</td>\n",
       "      <td>5.780910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.658537</td>\n",
       "      <td>9.408181</td>\n",
       "      <td>0.330357</td>\n",
       "      <td>5.504756</td>\n",
       "      <td>0.107843</td>\n",
       "      <td>2.020632</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>9.295912</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>7.242210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419643</td>\n",
       "      <td>9.855467</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>18.611555</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>6.524563</td>\n",
       "      <td>0.883929</td>\n",
       "      <td>5.013162</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>6.913590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.658537</td>\n",
       "      <td>11.146350</td>\n",
       "      <td>0.383929</td>\n",
       "      <td>6.946706</td>\n",
       "      <td>0.107843</td>\n",
       "      <td>1.934609</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>8.030827</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>9.884404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401786</td>\n",
       "      <td>8.958074</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>20.284845</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>4.193433</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>5.404426</td>\n",
       "      <td>0.240385</td>\n",
       "      <td>5.384228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.695122</td>\n",
       "      <td>9.807899</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>5.312036</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>1.874545</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>7.932706</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>7.608558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>8.033159</td>\n",
       "      <td>0.513889</td>\n",
       "      <td>12.157357</td>\n",
       "      <td>0.410714</td>\n",
       "      <td>5.657496</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>6.224210</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>7.245308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.670732</td>\n",
       "      <td>9.855147</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>4.767713</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>2.163522</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>6.008308</td>\n",
       "      <td>0.580357</td>\n",
       "      <td>5.676947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383929</td>\n",
       "      <td>8.536510</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>19.991161</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>6.494547</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>4.558971</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>5.439619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.682927</td>\n",
       "      <td>10.656850</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>9.404527</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>2.183964</td>\n",
       "      <td>0.241071</td>\n",
       "      <td>7.680702</td>\n",
       "      <td>0.517857</td>\n",
       "      <td>9.589148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401786</td>\n",
       "      <td>9.395132</td>\n",
       "      <td>0.347222</td>\n",
       "      <td>21.234489</td>\n",
       "      <td>0.419643</td>\n",
       "      <td>5.438184</td>\n",
       "      <td>0.866071</td>\n",
       "      <td>5.388599</td>\n",
       "      <td>0.201923</td>\n",
       "      <td>4.043894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.646341</td>\n",
       "      <td>9.233398</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>10.406850</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>1.824014</td>\n",
       "      <td>0.258929</td>\n",
       "      <td>8.847640</td>\n",
       "      <td>0.589286</td>\n",
       "      <td>11.312515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383929</td>\n",
       "      <td>9.092612</td>\n",
       "      <td>0.402778</td>\n",
       "      <td>16.249327</td>\n",
       "      <td>0.419643</td>\n",
       "      <td>6.248868</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>5.901835</td>\n",
       "      <td>0.355769</td>\n",
       "      <td>5.329819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.682927</td>\n",
       "      <td>11.198006</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>6.539944</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>2.085662</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>12.815554</td>\n",
       "      <td>0.517857</td>\n",
       "      <td>7.735493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>13.095354</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>19.086979</td>\n",
       "      <td>0.473214</td>\n",
       "      <td>5.433387</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>4.840829</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>5.936163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.658537</td>\n",
       "      <td>11.821955</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>5.887434</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>2.112489</td>\n",
       "      <td>0.258929</td>\n",
       "      <td>8.508211</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>5.115957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>11.163805</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>22.781647</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>5.098855</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>5.715331</td>\n",
       "      <td>0.259615</td>\n",
       "      <td>5.770248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.646341</td>\n",
       "      <td>9.691713</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>8.060163</td>\n",
       "      <td>0.107843</td>\n",
       "      <td>2.072417</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>7.356790</td>\n",
       "      <td>0.598214</td>\n",
       "      <td>6.804909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>8.497550</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20.727972</td>\n",
       "      <td>0.401786</td>\n",
       "      <td>5.155658</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>5.899515</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4.432584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.609756</td>\n",
       "      <td>9.917165</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>5.611570</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>7.011961</td>\n",
       "      <td>0.544643</td>\n",
       "      <td>7.543925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>12.011959</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>15.449226</td>\n",
       "      <td>0.401786</td>\n",
       "      <td>5.403032</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>5.219247</td>\n",
       "      <td>0.259615</td>\n",
       "      <td>5.783682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.634146</td>\n",
       "      <td>9.973485</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>6.776517</td>\n",
       "      <td>0.107843</td>\n",
       "      <td>2.062280</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>6.070012</td>\n",
       "      <td>0.580357</td>\n",
       "      <td>9.925593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401786</td>\n",
       "      <td>10.002164</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>19.544659</td>\n",
       "      <td>0.366071</td>\n",
       "      <td>5.838468</td>\n",
       "      <td>0.866071</td>\n",
       "      <td>7.620860</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>5.939365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.621951</td>\n",
       "      <td>8.868321</td>\n",
       "      <td>0.366071</td>\n",
       "      <td>5.738019</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>2.034117</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>7.951857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>9.228404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294643</td>\n",
       "      <td>10.243076</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>15.528419</td>\n",
       "      <td>0.419643</td>\n",
       "      <td>5.690563</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>5.946645</td>\n",
       "      <td>0.240385</td>\n",
       "      <td>5.531962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.609756</td>\n",
       "      <td>9.756155</td>\n",
       "      <td>0.330357</td>\n",
       "      <td>7.348890</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>2.055173</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>5.144898</td>\n",
       "      <td>0.580357</td>\n",
       "      <td>7.699546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>9.692498</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>20.009516</td>\n",
       "      <td>0.419643</td>\n",
       "      <td>4.471452</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>3.091824</td>\n",
       "      <td>0.298077</td>\n",
       "      <td>6.618144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.670732</td>\n",
       "      <td>8.480314</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>7.888321</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>1.926160</td>\n",
       "      <td>0.241071</td>\n",
       "      <td>6.804184</td>\n",
       "      <td>0.580357</td>\n",
       "      <td>13.068426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>8.039388</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>25.184732</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>5.527239</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>5.062254</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>6.181662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.609756</td>\n",
       "      <td>9.694124</td>\n",
       "      <td>0.366071</td>\n",
       "      <td>7.566572</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>1.950150</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>8.594522</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>9.783302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455357</td>\n",
       "      <td>7.704805</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>15.011940</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>4.214575</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>6.052769</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>4.638736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.634146</td>\n",
       "      <td>9.129755</td>\n",
       "      <td>0.366071</td>\n",
       "      <td>9.134881</td>\n",
       "      <td>0.107843</td>\n",
       "      <td>1.838882</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>4.499615</td>\n",
       "      <td>0.544643</td>\n",
       "      <td>10.048374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>9.679211</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>11.079523</td>\n",
       "      <td>0.410714</td>\n",
       "      <td>6.202335</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>3.012310</td>\n",
       "      <td>0.278846</td>\n",
       "      <td>6.225877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.658537</td>\n",
       "      <td>9.632875</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>6.922334</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>1.859216</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>6.968392</td>\n",
       "      <td>0.544643</td>\n",
       "      <td>10.675591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383929</td>\n",
       "      <td>8.156558</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>18.708851</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>7.111330</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>6.139552</td>\n",
       "      <td>0.221154</td>\n",
       "      <td>5.139540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.695122</td>\n",
       "      <td>9.014029</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>5.750155</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>2.024086</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>5.250049</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>6.452072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>8.478461</td>\n",
       "      <td>0.513889</td>\n",
       "      <td>20.097576</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>5.820951</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>6.451217</td>\n",
       "      <td>0.298077</td>\n",
       "      <td>5.572271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.707317</td>\n",
       "      <td>10.240438</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>7.187042</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>1.989335</td>\n",
       "      <td>0.294643</td>\n",
       "      <td>9.511210</td>\n",
       "      <td>0.526786</td>\n",
       "      <td>9.031456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401786</td>\n",
       "      <td>10.425301</td>\n",
       "      <td>0.430556</td>\n",
       "      <td>18.669436</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>5.140524</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>5.469726</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>4.448575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.719512</td>\n",
       "      <td>9.387044</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>6.707863</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>2.999838</td>\n",
       "      <td>0.348214</td>\n",
       "      <td>8.190573</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>11.048841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>9.825673</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>17.612230</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>4.218857</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>6.550789</td>\n",
       "      <td>0.317308</td>\n",
       "      <td>4.743973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.634146</td>\n",
       "      <td>9.603584</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>7.866797</td>\n",
       "      <td>0.107843</td>\n",
       "      <td>1.953239</td>\n",
       "      <td>0.294643</td>\n",
       "      <td>6.052293</td>\n",
       "      <td>0.508929</td>\n",
       "      <td>12.011832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383929</td>\n",
       "      <td>8.078341</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>16.924274</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>4.319098</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>3.767711</td>\n",
       "      <td>0.221154</td>\n",
       "      <td>6.060121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.658537</td>\n",
       "      <td>8.830215</td>\n",
       "      <td>0.348214</td>\n",
       "      <td>7.774788</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>2.119072</td>\n",
       "      <td>0.294643</td>\n",
       "      <td>5.960194</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>11.796387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401786</td>\n",
       "      <td>10.463970</td>\n",
       "      <td>0.513889</td>\n",
       "      <td>18.318304</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>7.843558</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>4.424201</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>15.277728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.682927</td>\n",
       "      <td>9.321712</td>\n",
       "      <td>0.366071</td>\n",
       "      <td>6.338528</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>1.950804</td>\n",
       "      <td>0.241071</td>\n",
       "      <td>8.733125</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>6.465158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>9.665541</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>11.560870</td>\n",
       "      <td>0.401786</td>\n",
       "      <td>6.928295</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>5.890048</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>5.667637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26 rows Ã— 4004 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0          1         2          3         4         5         6     \\\n",
       "0   0.658537   7.738423  0.392857   7.900820  0.098039  2.199746  0.241071   \n",
       "1   0.670732   6.932831  0.339286   7.754910  0.098039  2.031164  0.303571   \n",
       "2   0.597561   8.786510  0.366071   6.649922  0.098039  1.931009  0.303571   \n",
       "3   0.658537   9.408181  0.330357   5.504756  0.107843  2.020632  0.285714   \n",
       "4   0.658537  11.146350  0.383929   6.946706  0.107843  1.934609  0.285714   \n",
       "5   0.695122   9.807899  0.357143   5.312036  0.098039  1.874545  0.312500   \n",
       "6   0.670732   9.855147  0.312500   4.767713  0.117647  2.163522  0.276786   \n",
       "7   0.682927  10.656850  0.312500   9.404527  0.098039  2.183964  0.241071   \n",
       "8   0.646341   9.233398  0.375000  10.406850  0.098039  1.824014  0.258929   \n",
       "9   0.682927  11.198006  0.357143   6.539944  0.098039  2.085662  0.285714   \n",
       "10  0.658537  11.821955  0.392857   5.887434  0.098039  2.112489  0.258929   \n",
       "11  0.646341   9.691713  0.339286   8.060163  0.107843  2.072417  0.276786   \n",
       "12  0.609756   9.917165  0.375000   5.611570  0.098039  2.100175  0.285714   \n",
       "13  0.634146   9.973485  0.312500   6.776517  0.107843  2.062280  0.250000   \n",
       "14  0.621951   8.868321  0.366071   5.738019  0.098039  2.034117  0.276786   \n",
       "15  0.609756   9.756155  0.330357   7.348890  0.078431  2.055173  0.232143   \n",
       "16  0.670732   8.480314  0.392857   7.888321  0.098039  1.926160  0.241071   \n",
       "17  0.609756   9.694124  0.366071   7.566572  0.098039  1.950150  0.232143   \n",
       "18  0.634146   9.129755  0.366071   9.134881  0.107843  1.838882  0.303571   \n",
       "19  0.658537   9.632875  0.357143   6.922334  0.098039  1.859216  0.276786   \n",
       "20  0.695122   9.014029  0.357143   5.750155  0.098039  2.024086  0.276786   \n",
       "21  0.707317  10.240438  0.339286   7.187042  0.098039  1.989335  0.294643   \n",
       "22  0.719512   9.387044  0.357143   6.707863  0.117647  2.999838  0.348214   \n",
       "23  0.634146   9.603584  0.357143   7.866797  0.107843  1.953239  0.294643   \n",
       "24  0.658537   8.830215  0.348214   7.774788  0.088235  2.119072  0.294643   \n",
       "25  0.682927   9.321712  0.366071   6.338528  0.098039  1.950804  0.241071   \n",
       "\n",
       "         7         8          9     ...      3994       3995      3996  \\\n",
       "0    4.738143  0.491071   6.531595  ...  0.375000   8.045144  0.486111   \n",
       "1    6.846100  0.535714   7.235452  ...  0.410714   9.098060  0.375000   \n",
       "2    5.858680  0.580357   7.380602  ...  0.410714  10.986277  0.458333   \n",
       "3    9.295912  0.535714   7.242210  ...  0.419643   9.855467  0.486111   \n",
       "4    8.030827  0.482143   9.884404  ...  0.401786   8.958074  0.388889   \n",
       "5    7.932706  0.535714   7.608558  ...  0.375000   8.033159  0.513889   \n",
       "6    6.008308  0.580357   5.676947  ...  0.383929   8.536510  0.458333   \n",
       "7    7.680702  0.517857   9.589148  ...  0.401786   9.395132  0.347222   \n",
       "8    8.847640  0.589286  11.312515  ...  0.383929   9.092612  0.402778   \n",
       "9   12.815554  0.517857   7.735493  ...  0.446429  13.095354  0.375000   \n",
       "10   8.508211  0.535714   5.115957  ...  0.428571  11.163805  0.444444   \n",
       "11   7.356790  0.598214   6.804909  ...  0.428571   8.497550  0.500000   \n",
       "12   7.011961  0.544643   7.543925  ...  0.339286  12.011959  0.444444   \n",
       "13   6.070012  0.580357   9.925593  ...  0.401786  10.002164  0.500000   \n",
       "14   7.951857  0.571429   9.228404  ...  0.294643  10.243076  0.472222   \n",
       "15   5.144898  0.580357   7.699546  ...  0.375000   9.692498  0.527778   \n",
       "16   6.804184  0.580357  13.068426  ...  0.428571   8.039388  0.458333   \n",
       "17   8.594522  0.571429   9.783302  ...  0.455357   7.704805  0.458333   \n",
       "18   4.499615  0.544643  10.048374  ...  0.375000   9.679211  0.416667   \n",
       "19   6.968392  0.544643  10.675591  ...  0.383929   8.156558  0.486111   \n",
       "20   5.250049  0.553571   6.452072  ...  0.428571   8.478461  0.513889   \n",
       "21   9.511210  0.526786   9.031456  ...  0.401786  10.425301  0.430556   \n",
       "22   8.190573  0.535714  11.048841  ...  0.392857   9.825673  0.486111   \n",
       "23   6.052293  0.508929  12.011832  ...  0.383929   8.078341  0.500000   \n",
       "24   5.960194  0.562500  11.796387  ...  0.401786  10.463970  0.513889   \n",
       "25   8.733125  0.482143   6.465158  ...  0.437500   9.665541  0.416667   \n",
       "\n",
       "         3997      3998      3999      4000      4001      4002       4003  \n",
       "0   14.517509  0.401786  6.404209  0.812500  4.759510  0.298077   5.525523  \n",
       "1   14.165912  0.455357  5.934387  0.848214  5.642019  0.298077   5.054339  \n",
       "2   12.965539  0.392857  6.995210  0.848214  5.816529  0.240385   5.780910  \n",
       "3   18.611555  0.437500  6.524563  0.883929  5.013162  0.250000   6.913590  \n",
       "4   20.284845  0.446429  4.193433  0.839286  5.404426  0.240385   5.384228  \n",
       "5   12.157357  0.410714  5.657496  0.875000  6.224210  0.230769   7.245308  \n",
       "6   19.991161  0.437500  6.494547  0.875000  4.558971  0.307692   5.439619  \n",
       "7   21.234489  0.419643  5.438184  0.866071  5.388599  0.201923   4.043894  \n",
       "8   16.249327  0.419643  6.248868  0.812500  5.901835  0.355769   5.329819  \n",
       "9   19.086979  0.473214  5.433387  0.821429  4.840829  0.288462   5.936163  \n",
       "10  22.781647  0.437500  5.098855  0.857143  5.715331  0.259615   5.770248  \n",
       "11  20.727972  0.401786  5.155658  0.803571  5.899515  0.250000   4.432584  \n",
       "12  15.449226  0.401786  5.403032  0.803571  5.219247  0.259615   5.783682  \n",
       "13  19.544659  0.366071  5.838468  0.866071  7.620860  0.192308   5.939365  \n",
       "14  15.528419  0.419643  5.690563  0.848214  5.946645  0.240385   5.531962  \n",
       "15  20.009516  0.419643  4.471452  0.857143  3.091824  0.298077   6.618144  \n",
       "16  25.184732  0.392857  5.527239  0.812500  5.062254  0.230769   6.181662  \n",
       "17  15.011940  0.339286  4.214575  0.830357  6.052769  0.346154   4.638736  \n",
       "18  11.079523  0.410714  6.202335  0.848214  3.012310  0.278846   6.225877  \n",
       "19  18.708851  0.428571  7.111330  0.830357  6.139552  0.221154   5.139540  \n",
       "20  20.097576  0.437500  5.820951  0.839286  6.451217  0.298077   5.572271  \n",
       "21  18.669436  0.428571  5.140524  0.714286  5.469726  0.346154   4.448575  \n",
       "22  17.612230  0.446429  4.218857  0.848214  6.550789  0.317308   4.743973  \n",
       "23  16.924274  0.446429  4.319098  0.839286  3.767711  0.221154   6.060121  \n",
       "24  18.318304  0.392857  7.843558  0.839286  4.424201  0.192308  15.277728  \n",
       "25  11.560870  0.401786  6.928295  0.821429  5.890048  0.326923   5.667637  \n",
       "\n",
       "[26 rows x 4004 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
